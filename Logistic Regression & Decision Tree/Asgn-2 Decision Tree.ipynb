{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "import math\n",
    "import pprint\n",
    "from numpy import log2 as log \n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets (write the path to the .csv file below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:/Users/Shikhar/Desktop/ML/Asgn-2/data/winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all the values in quality attribute to 0 (bad) if the value is less than or equal to ‘6’ and others to 1(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data['quality']\n",
    "for i in range(len(x)):\n",
    "    if(x[i] <5):\n",
    "        x[i]=0\n",
    "    elif(x[i]==5 or x[i]==6):\n",
    "        x[i]=1\n",
    "    else:\n",
    "        x[i]=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Score Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "s='fixed acidity'\n",
    "data[s]=(data[s]-data[s].mean())/(data[s].std())\n",
    "\n",
    "\n",
    "s='volatile acidity'\n",
    "data[s]=(data[s]-data[s].mean())/(data[s].std())\n",
    "\n",
    "s='citric acid'\n",
    "data[s]=(data[s]-data[s].mean())/(data[s].std())\n",
    "\n",
    "s='residual sugar'\n",
    "data[s]=(data[s]-data[s].mean())/(data[s].std())\n",
    "\n",
    "s='chlorides'\n",
    "data[s]=(data[s]-data[s].mean())/(data[s].std())\n",
    "\n",
    "s='free sulfur dioxide'\n",
    "data[s]=(data[s]-data[s].mean())/(data[s].std())\n",
    "\n",
    "s='total sulfur dioxide'\n",
    "data[s]=(data[s]-data[s].mean())/(data[s].std())\n",
    "\n",
    "s='density'\n",
    "data[s]=(data[s]-data[s].mean())/(data[s].std())\n",
    "\n",
    "s='pH'\n",
    "data[s]=(data[s]-data[s].mean())/(data[s].std())\n",
    "\n",
    "s='sulphates'\n",
    "data[s]=(data[s]-data[s].mean())/(data[s].std())\n",
    "\n",
    "s='alcohol'\n",
    "data[s]=(data[s]-data[s].mean())/(data[s].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segregation of data into 4 equally spaced bins represented as 0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = pd.cut(data['fixed acidity'], 4, labels=['0','1','2','3'], precision=100)\n",
    "data.drop(['fixed acidity'], inplace=True, axis=1)\n",
    "data.insert(0, 'fixed acidity', category)\n",
    "\n",
    "category = pd.cut(data['volatile acidity'], 4, labels=['0','1','2','3'], precision=100)\n",
    "data.drop(['volatile acidity'], inplace=True, axis=1)\n",
    "data.insert(1, 'volatile acidity', category)\n",
    "\n",
    "category = pd.cut(data['citric acid'], 4, labels=['0','1','2','3'], precision=100)\n",
    "data.drop(['citric acid'], inplace=True, axis=1)\n",
    "data.insert(2, 'citric acid', category)\n",
    "\n",
    "category = pd.cut(data['residual sugar'], 4, labels=['0','1','2','3'], precision=100)\n",
    "data.drop(['residual sugar'], inplace=True, axis=1)\n",
    "data.insert(3, 'residual sugar', category)\n",
    "\n",
    "category = pd.cut(data['chlorides'], 4, labels=['0','1','2','3'], precision=100)\n",
    "data.drop(['chlorides'], inplace=True, axis=1)\n",
    "data.insert(4, 'chlorides', category)\n",
    "\n",
    "category = pd.cut(data['free sulfur dioxide'], 4, labels=['0','1','2','3'], precision=100)\n",
    "data.drop(['free sulfur dioxide'], inplace=True, axis=1)\n",
    "data.insert(5, 'free sulfur dioxide', category)\n",
    "\n",
    "category = pd.cut(data['total sulfur dioxide'], 4, labels=['0','1','2','3'], precision=100)\n",
    "data.drop(['total sulfur dioxide'], inplace=True, axis=1)\n",
    "data.insert(6, 'total sulfur dioxide', category)\n",
    "\n",
    "category = pd.cut(data['density'], 4, labels=['0','1','2','3'], precision=100)\n",
    "data.drop(['density'], inplace=True, axis=1)\n",
    "data.insert(7, 'density', category)\n",
    "\n",
    "category = pd.cut(data['pH'], 4, labels=['0','1','2','3'], precision=100)\n",
    "data.drop(['pH'], inplace=True, axis=1)\n",
    "data.insert(8, 'pH', category)\n",
    "\n",
    "category = pd.cut(data['sulphates'], 4, labels=['0','1','2','3'], precision=100)\n",
    "data.drop(['sulphates'], inplace=True, axis=1)\n",
    "data.insert(9, 'sulphates', category)\n",
    "\n",
    "category = pd.cut(data['alcohol'], 4, labels=['0','1','2','3'], precision=100)\n",
    "data.drop(['alcohol'], inplace=True, axis=1)\n",
    "data.insert(10, 'alcohol', category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['quality']\n",
    "X=data.drop(['quality'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset is ready for Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3 Decision tree using Information Gain in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Breaking the dataset into train and test dataset\n",
    "\n",
    "m=len(y)\n",
    "train=[]\n",
    "test=[]\n",
    "Y=[]\n",
    "for j in range(m//3,m):\n",
    "    l=[]\n",
    "    Y.append(y[j])\n",
    "    for i in range(0,11):\n",
    "        l.append(int(X[j][i]))\n",
    "    l.append(int(y[j]))\n",
    "    train.append(l)\n",
    "for j in range(0,m//3):\n",
    "    l=[]\n",
    "    for i in range(0,11):\n",
    "        l.append(int(X[j][i]))\n",
    "    l.append(int(y[j]))\n",
    "    test.append(l)\n",
    "    \n",
    "dataset=pd.DataFrame(train,columns=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol','quality'])\n",
    "testdataset=pd.DataFrame(test,columns=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol','quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(Column):\n",
    "    elements,counts = np.unique(Column,return_counts = True)\n",
    "    m=len(elements)\n",
    "    for i in range(0,m):\n",
    "        entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])   #Entropy of each node is found out using the formula taught\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InformationGain(data,split_attribute_name,target_name=\"quality\"):\n",
    "    total_entropy = entropy(data[target_name]) \n",
    "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "    Information_Gain = total_entropy - Weighted_Entropy      #Info-gain is found put using the entropy function above\n",
    "    return Information_Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Decision Tree function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Decision_Tree(data,originaldata,features,target_attribute_name=\"quality\",parent_node_class = None):\n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
    "        return np.unique(data[target_attribute_name])[0]\n",
    "    \n",
    "    elif len(data)<10:\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
    "    \n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class    \n",
    "    else:\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
    "        item_values = [InformationGain(data,feature,target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset\n",
    "        best_feature_index = np.argmax(item_values)\n",
    "        best_feature = features[best_feature_index]\n",
    "        tree = {best_feature:{}}\n",
    "        features = [i for i in features if i != best_feature]        \n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            subtree = Build_Decision_Tree(sub_data,dataset,features,target_attribute_name,parent_node_class)\n",
    "            tree[best_feature][value] = subtree\n",
    "        return(tree)   \n",
    "    \n",
    "Tree=Build_Decision_Tree(dataset,dataset,dataset.columns[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold cross validation on Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Accuracy from basic decision tree: 0.8311444652908068\n",
      "Macro Precision from basic decision tree: 0.43720930232558136\n",
      "Macro Recall from basic decision tree: 0.3520767202431938\n"
     ]
    }
   ],
   "source": [
    "# Prediction function for the decision tree\n",
    "\n",
    "def predict(query,tree):\n",
    "    for key in list(query.keys()):\n",
    "        if key in list(tree.keys()):\n",
    "            try:\n",
    "                result = tree[key][query[key]] \n",
    "            except:\n",
    "                return 1\n",
    "            result = tree[key][query[key]]\n",
    "            if isinstance(result,dict):\n",
    "                return predict(query,result)\n",
    "            else:\n",
    "                return result\n",
    "queries=testdataset.iloc[:,:-1].to_dict(orient = \"records\")\n",
    "count=0\n",
    "\n",
    "#1st fold cross validation\n",
    "\n",
    "True_Positive=0\n",
    "True_Negative=0\n",
    "False_Positive=0\n",
    "False_Negative=0\n",
    "Y=[]\n",
    "for i in range(0,m//3):\n",
    "    y_pred=predict(queries[i],Tree)\n",
    "    Y.append(y_pred)\n",
    "    if(y_pred==y[i]):\n",
    "        if(y[i]==1):\n",
    "            True_Positive+=1\n",
    "        else:\n",
    "            True_Negative+=1\n",
    "    else:\n",
    "        if(y_pred==1):\n",
    "            False_Positive+=1\n",
    "        else:\n",
    "            False_Negative+=1\n",
    "            \n",
    "Accuracy_1=(True_Positive+True_Negative)/(True_Positive+True_Negative+False_Negative+False_Positive)\n",
    "Precision_1=True_Positive/(True_Positive+False_Positive)\n",
    "Recall_1=True_Positive/(True_Positive+False_Negative)\n",
    "\n",
    "\n",
    "#2nd fold cross validation\n",
    "\n",
    "True_Positive=0\n",
    "True_Negative=0\n",
    "False_Positive=0\n",
    "False_Negative=0\n",
    "for i in range(0,m//3):\n",
    "    y_pred=Y[i]\n",
    "    if(y_pred==y[i]):\n",
    "        if(y[i]==0):\n",
    "            True_Positive+=1\n",
    "        else:\n",
    "            True_Negative+=1\n",
    "    else:\n",
    "        if(y_pred==0):\n",
    "            False_Positive+=1\n",
    "        else:\n",
    "            False_Negative+=1\n",
    "            \n",
    "Accuracy_2=(True_Positive+True_Negative)/(True_Positive+True_Negative+False_Negative+False_Positive)\n",
    "count=0\n",
    "if(True_Positive+False_Positive==0):\n",
    "    count+=1\n",
    "    Precision_2=0\n",
    "else:\n",
    "    Precision_2=True_Positive/(True_Positive+False_Positive)\n",
    "Recall_2=True_Positive/(True_Positive+False_Negative)\n",
    "\n",
    "#3rd fold cross validation\n",
    "\n",
    "True_Positive=0\n",
    "True_Negative=0\n",
    "False_Positive=0\n",
    "False_Negative=0\n",
    "for i in range(0,m//3):\n",
    "    y_pred=Y[i]\n",
    "    if(y_pred==y[i]):\n",
    "        if(y[i]==2):\n",
    "            True_Positive+=1\n",
    "        else:\n",
    "            True_Negative+=1\n",
    "    else:\n",
    "        if(y_pred==2):\n",
    "            False_Positive+=1\n",
    "        else:\n",
    "            False_Negative+=1\n",
    "            \n",
    "Accuracy_3=(True_Positive+True_Negative)/(True_Positive+True_Negative+False_Negative+False_Positive)\n",
    "if(True_Positive+False_Positive==0):\n",
    "    Precision_3=0\n",
    "    count+=1\n",
    "else:\n",
    "    Precision_3=True_Positive/(True_Positive+False_Positive)\n",
    "Recall_3=True_Positive/(True_Positive+False_Negative)\n",
    "\n",
    "#Printing results 3-fold cross validation\n",
    "\n",
    "print(\"Macro Accuracy from basic decision tree:\",(Accuracy_1+Accuracy_2+Accuracy_3)/3)\n",
    "print(\"Macro Precision from basic decision tree:\",(Precision_1+Precision_2+Precision_3)/(3))\n",
    "print(\"Macro Recall from basic decision tree:\",(Recall_1+Recall_2+Recall_3)/(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree building using scikitlearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score from scikit learn Decision Tree is : 0.8480300187617261\n",
      "Precision Score from scikit learn Decision Tree is : 0.544021444082519\n",
      "Recall Score from scikit learn Decision Tree is : 0.406852931688462\n"
     ]
    }
   ],
   "source": [
    "model=DecisionTreeClassifier(criterion='entropy', max_depth=4,  min_samples_split=10)\n",
    "model.fit(X,y)\n",
    "y_predict = model.predict(X)\n",
    "print(\"Accuracy Score from scikit learn Decision Tree is :\", accuracy_score(y,y_predict))\n",
    "print(\"Precision Score from scikit learn Decision Tree is :\", precision_score(y,y_predict, average='macro'))\n",
    "print(\"Recall Score from scikit learn Decision Tree is :\", recall_score(y,y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold cross validation using scikit learn (k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score from scikit learn Decision Tree is : 0.8311358710314444\n"
     ]
    }
   ],
   "source": [
    "model=DecisionTreeClassifier(criterion='entropy', max_depth=4,  min_samples_split=10)\n",
    "\n",
    "print(\"Accuracy score from scikit learn Decision Tree is :\", cross_val_score(model,X,y,cv=3).mean())    #Mean accuracy using k-fold cross validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
